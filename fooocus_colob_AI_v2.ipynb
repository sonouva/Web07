{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonouva/Web07/blob/master/fooocus_colob_AI_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e3e222-7dba-4cc3-e176-8f0de29ab323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygit2==1.15.1\n",
            "  Downloading pygit2-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: cffi>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pygit2==1.15.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.16.0->pygit2==1.15.1) (2.22)\n",
            "Downloading pygit2-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygit2\n",
            "  Attempting uninstall: pygit2\n",
            "    Found existing installation: pygit2 1.18.0\n",
            "    Uninstalling pygit2-1.18.0:\n",
            "      Successfully uninstalled pygit2-1.18.0\n",
            "Successfully installed pygit2-1.15.1\n",
            "/content\n",
            "Cloning into 'Fooocus'...\n",
            "remote: Enumerating objects: 6725, done.\u001b[K\n",
            "remote: Total 6725 (delta 0), reused 0 (delta 0), pack-reused 6725 (from 1)\u001b[K\n",
            "Receiving objects: 100% (6725/6725), 33.33 MiB | 20.80 MiB/s, done.\n",
            "Resolving deltas: 100% (3854/3854), done.\n",
            "/content/Fooocus\n"
          ]
        }
      ],
      "source": [
        "!pip install pygit2==1.15.1\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/Fooocus.git\n",
        "%cd /content/Fooocus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/Fooocus/models/checkpoints/realismEngineSDXL_v30VAE.safetensors https://civitai.com/api/download/models/1920523"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnatfZ8EfBXi",
        "outputId": "9c0249ba-4fbd-4201-aea6-e26896ba033c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-14 11:33:38--  https://civitai.com/api/download/models/1920523\n",
            "Resolving civitai.com (civitai.com)... 172.67.12.143, 172.66.152.186, 2606:4700:10::ac42:98ba, ...\n",
            "Connecting to civitai.com (civitai.com)|172.67.12.143|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/model/81744/epicrealismxl.NC5J.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22epicrealismXL_vxviiCrystalclear.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250714/us-east-1/s3/aws4_request&X-Amz-Date=20250714T113338Z&X-Amz-SignedHeaders=host&X-Amz-Signature=94d657fac4a1ac0066936f542ce2740ba2658277ac2b347f65b9fc06d185fcf3 [following]\n",
            "--2025-07-14 11:33:38--  https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/model/81744/epicrealismxl.NC5J.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22epicrealismXL_vxviiCrystalclear.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250714/us-east-1/s3/aws4_request&X-Amz-Date=20250714T113338Z&X-Amz-SignedHeaders=host&X-Amz-Signature=94d657fac4a1ac0066936f542ce2740ba2658277ac2b347f65b9fc06d185fcf3\n",
            "Resolving civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)... 172.66.1.46, 162.159.141.50, 2606:4700:7::12e, ...\n",
            "Connecting to civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)|172.66.1.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6938062130 (6.5G)\n",
            "Saving to: ‘/content/Fooocus/models/checkpoints/realismEngineSDXL_v30VAE.safetensors’\n",
            "\n",
            "/content/Fooocus/mo 100%[===================>]   6.46G  63.3MB/s    in 63s     \n",
            "\n",
            "2025-07-14 11:34:42 (105 MB/s) - ‘/content/Fooocus/models/checkpoints/realismEngineSDXL_v30VAE.safetensors’ saved [6938062130/6938062130]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/Fooocus/models/checkpoints/lazymixRealAmateur_v40.safetensors https://civitai.com/api/download/models/300972"
      ],
      "metadata": {
        "id": "QepP8aXzfBe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95ec9436-3f88-4668-a4e9-9fee79d6b102"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-14 11:34:47--  https://civitai.com/api/download/models/300972\n",
            "Resolving civitai.com (civitai.com)... 172.67.12.143, 172.66.152.186, 2606:4700:10::ac43:c8f, ...\n",
            "Connecting to civitai.com (civitai.com)|172.67.12.143|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/model/15946/lazyplusV4Fp16VAE.mSoW.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22lazymixRealAmateur_v40.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250714/us-east-1/s3/aws4_request&X-Amz-Date=20250714T113447Z&X-Amz-SignedHeaders=host&X-Amz-Signature=eb42aa6cdd57896eefbf126696192b07fc1cebf87bdf4d05cec6310c64288b38 [following]\n",
            "--2025-07-14 11:34:47--  https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/model/15946/lazyplusV4Fp16VAE.mSoW.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22lazymixRealAmateur_v40.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250714/us-east-1/s3/aws4_request&X-Amz-Date=20250714T113447Z&X-Amz-SignedHeaders=host&X-Amz-Signature=eb42aa6cdd57896eefbf126696192b07fc1cebf87bdf4d05cec6310c64288b38\n",
            "Resolving civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)... 162.159.141.50, 172.66.1.46, 2a06:98c1:58::12e, ...\n",
            "Connecting to civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)|162.159.141.50|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4244149062 (4.0G) [application/octet-stream]\n",
            "Saving to: ‘/content/Fooocus/models/checkpoints/lazymixRealAmateur_v40.safetensors’\n",
            "\n",
            "/content/Fooocus/mo 100%[===================>]   3.95G  52.9MB/s    in 57s     \n",
            "\n",
            "2025-07-14 11:35:44 (71.5 MB/s) - ‘/content/Fooocus/models/checkpoints/lazymixRealAmateur_v40.safetensors’ saved [4244149062/4244149062]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/Fooocus/models/checkpoints/chinese_doll_idol.safetensors https://civitai.com/api/download/models/81566?type=Model&format=SafeTensor"
      ],
      "metadata": {
        "id": "sdfAz1HVhAFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5b4f76-50d8-4039-fa8c-cf28b24d4e49"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-14 11:49:53--  https://civitai.com/api/download/models/81566?type=Model\n",
            "Resolving civitai.com (civitai.com)... 172.67.12.143, 172.66.152.186, 2606:4700:10::ac42:98ba, ...\n",
            "Connecting to civitai.com (civitai.com)|172.67.12.143|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/731699/model/chinesedollidolv1.PucU.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22chinesedollidolv1.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250714/us-east-1/s3/aws4_request&X-Amz-Date=20250714T114953Z&X-Amz-SignedHeaders=host&X-Amz-Signature=adce9934e1e1b7c291f2e44a286f3522a2b7c38481e585bf7c352314d0045691 [following]\n",
            "--2025-07-14 11:49:53--  https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/731699/model/chinesedollidolv1.PucU.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22chinesedollidolv1.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250714/us-east-1/s3/aws4_request&X-Amz-Date=20250714T114953Z&X-Amz-SignedHeaders=host&X-Amz-Signature=adce9934e1e1b7c291f2e44a286f3522a2b7c38481e585bf7c352314d0045691\n",
            "Resolving civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)... 172.66.1.46, 162.159.141.50, 2606:4700:7::12e, ...\n",
            "Connecting to civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)|172.66.1.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 151115972 (144M) [application/octet-stream]\n",
            "Saving to: ‘/content/Fooocus/models/checkpoints/chinese_doll_idol.safetensors’\n",
            "\n",
            "/content/Fooocus/mo 100%[===================>] 144.12M   120MB/s    in 1.2s    \n",
            "\n",
            "2025-07-14 11:49:54 (120 MB/s) - ‘/content/Fooocus/models/checkpoints/chinese_doll_idol.safetensors’ saved [151115972/151115972]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python entry_with_update.py --share --always-high-vram\n"
      ],
      "metadata": {
        "id": "f2vkl7TUfAWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42efd2a0-3d69-4719-fb6f-581b02312d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--always-high-vram']\n",
            "Python 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Fooocus version: 2.5.5\n",
            "[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n",
            "[Cleanup] Cleanup successful\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "Set vram state to: HIGH_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "Refiner unloaded.\n",
            "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Running on public URL: https://66bbff52a55d05386e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.1)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.59 seconds\n",
            "2025-07-14 11:50:47.016798: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752493847.279748   11244 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752493847.354171   11244 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-14 11:50:47.903954: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Started worker with PID 11185\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://66bbff52a55d05386e.gradio.live\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 168796137815612258\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1160, in handler\n",
            "    tasks, use_expansion, loras, current_progress = process_prompt(async_task, async_task.prompt, async_task.negative_prompt,\n",
            "                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 661, in process_prompt\n",
            "    pipeline.refresh_everything(refiner_model_name=async_task.refiner_model_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/default_pipeline.py\", line 250, in refresh_everything\n",
            "    refresh_base_model(base_model_name, vae_name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/default_pipeline.py\", line 74, in refresh_base_model\n",
            "    model_base = core.load_model(filename, vae_filename)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/core.py\", line 147, in load_model\n",
            "    unet, clip, vae, vae_filename, clip_vision = load_checkpoint_guess_config(ckpt_filename, embedding_directory=path_embeddings,\n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/sd.py\", line 449, in load_checkpoint_guess_config\n",
            "    model_config = model_detection.model_config_from_unet(sd, \"model.diffusion_model.\", unet_dtype)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/model_detection.py\", line 163, in model_config_from_unet\n",
            "    unet_config = detect_unet_config(state_dict, unet_key_prefix, dtype)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/model_detection.py\", line 49, in detect_unet_config\n",
            "    model_channels = state_dict['{}input_blocks.0.0.weight'.format(key_prefix)].shape[0]\n",
            "                     ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyError: 'model.diffusion_model.input_blocks.0.0.weight'\n",
            "Total time: 0.61 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 7384926201943493526\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 60 - 30\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1471, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 1160, in handler\n",
            "    tasks, use_expansion, loras, current_progress = process_prompt(async_task, async_task.prompt, async_task.negative_prompt,\n",
            "                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/async_worker.py\", line 661, in process_prompt\n",
            "    pipeline.refresh_everything(refiner_model_name=async_task.refiner_model_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/default_pipeline.py\", line 250, in refresh_everything\n",
            "    refresh_base_model(base_model_name, vae_name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/default_pipeline.py\", line 74, in refresh_base_model\n",
            "    model_base = core.load_model(filename, vae_filename)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/modules/core.py\", line 147, in load_model\n",
            "    unet, clip, vae, vae_filename, clip_vision = load_checkpoint_guess_config(ckpt_filename, embedding_directory=path_embeddings,\n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/sd.py\", line 449, in load_checkpoint_guess_config\n",
            "    model_config = model_detection.model_config_from_unet(sd, \"model.diffusion_model.\", unet_dtype)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/model_detection.py\", line 163, in model_config_from_unet\n",
            "    unet_config = detect_unet_config(state_dict, unet_key_prefix, dtype)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Fooocus/ldm_patched/modules/model_detection.py\", line 49, in detect_unet_config\n",
            "    model_channels = state_dict['{}input_blocks.0.0.weight'.format(key_prefix)].shape[0]\n",
            "                     ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyError: 'model.diffusion_model.input_blocks.0.0.weight'\n",
            "Total time: 0.05 seconds\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "name": "fooocus_colob_AI_v2.ipynb",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}